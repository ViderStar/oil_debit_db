# 1. Описание основных компонентов и их взаимодействия

## 1.1 Сбор данных (Data Ingestion)

- **Источники:**
  - Датчики ТМС (температура, давление и т. д.), установленные на ЭЦН (Электроцентробежные насосы).
  - Мгновенные замеры дебитов с АГЗУ (Автоматизированные групповые замерные установки).
  - Динамограммы с ШГН (Штанговых глубинных насосов).
  - Результаты лабораторных исследований добываемых флюидов.
  - Результаты гидродинамических исследований.
  - Техническая и производственная документация.
  - Данные о проведении мероприятий на скважинном оборудовании.
  - Информация о текущих и капитальных ремонтах.
  - Результаты расчётов на интегрированных моделях.

- **Методы и протоколы сбора:**
  - Приём данных через REST API (для внешних систем или устройств, умеющих отправлять HTTP-запросы).
  - Загрузка файлов (CSV, Excel, JSON) с лабораторными результатами и документацией.
  - Потоковая передача данных (streaming) из SCADA-систем или полевых устройств (при больших объёмах).

- **Выбор инструментов:**
  - Flask или FastAPI – лёгкие Python-фреймворки для разработки REST API (можно использовать Django при необходимости более сложного веб-приложения).
  - MQTT/Kafka (при высокочастотном сборе данных и необходимости потоковой обработки).

## 1.2 Хранение данных (Data Storage)

- **Реляционная БД** – Oracle для хранения структурированных данных (например, информация о ремонтах, техническая документация, результаты расчётов, журналы событий).
- **Столбцовая БД** – ClickHouse для аналитики больших объёмов данных с датчиков, логов, временных рядов. Позволяет быстро обрабатывать запросы к историческим данным.

- **Схема хранения:**
  - Oracle: несколько таблиц (например, MaintenanceRecords, WellDocs, LabResults и т. п.), где ключевые поля: id, well_id, date, description, result_data, doc_link и др.
  - ClickHouse: таблицы с временными рядами (например, SensorReadings, FlowRates, Dynamograms) с полями: timestamp, well_id, sensor_type, value.

## 1.3 Обработка и анализ данных (Data Processing & Analysis)

- **Основные фреймворки для анализа:**
  - Pandas – для первичной очистки и преобразования данных.
  - NumPy – для числовых вычислений, работы с большими массивами.
  - Scikit-learn – для классического машинного обучения (регрессия, классификация, кластеризация).
  - TensorFlow или PyTorch – если потребуется глубокое обучение (например, для распознавания паттернов в динамограммах или прогнозирования отказов оборудования).

- **Описание процесса:**
  - Из систем сбора данные попадают в очередь/буфер (например, Kafka), далее средствами Python-скриптов обрабатываются и очищаются (Pandas).
  - Загружаются в соответствующие хранилища (Oracle или ClickHouse).
  - Для обучения ML-моделей данные берутся выборочно из хранилища, проходят стадию предобработки (Pandas/NumPy).
  - Модель обучается (Scikit-learn/TensorFlow) и результаты прогнозов сохраняются обратно в базу или передаются в сервис визуализации.

- **Автоматизация:**
  - Возможна организация пайплайна с использованием Airflow или подобных инструментов для расписания (schedule) и оркестровки ETL/ELT-процессов.

## 1.4 Визуализация данных (Data Visualization)

- **Инструменты:**
  - Matplotlib и Seaborn – для статических графиков и детальной аналитики.
  - Plotly/Dash – для интерактивных онлайн-графиков и дашбордов, позволяющих пользователям взаимодействовать с данными (зум, фильтрация, переключение параметров).

- **Цели визуализации:**
  - Отображение показателей в реальном времени (дебиты, показатели датчиков).
  - Исторические тренды (динамограммы, давление, температура, производительность).
  - Результаты прогнозных моделей (прогноз отказа оборудования, оценка производительности).

## 1.5 Интерфейс пользователя (User Interface)

- **Веб-интерфейс:**
  - Страницы для просмотра текущих и исторических данных по каждой скважине.
  - Дашборды для визуализации ключевых параметров (дебит, давление, температура).
  - Разделы с аналитикой (результаты моделей, прогнозы по оборудованию).
  - Формы для загрузки документов и данных (лабораторные результаты, отчёты о ремонтах).
  - Отчёты в виде таблиц или PDF (генерация отчётов).

- **Технологии:**
  - Flask/FastAPI + фронтенд (React, Vue.js или Angular) – для быстрого создания REST API и клиентской части.
  - Или Django (полный стек) – если нужен более комплексный монолит с админ-панелью.

# 2. Дополнительные детали по взаимодействию компонентов

1. **Сбор данных:**
   - Приём данных по REST (Flask/FastAPI), сохранение во временное хранилище (например, Kafka) или сразу запись в ClickHouse/Oracle.
   - Файлы (CSV, Excel) через веб-интерфейс или автоматическую выгрузку в локальную папку, откуда скрипт ETL подбирает файлы.

2. **Предобработка:**
   - Python-скрипты с использованием Pandas и NumPy.
   - Для больших объёмов: Spark (опционально) – если требуется распределённая обработка.

3. **Обучение и предиктивная аналитика:**
   - Scikit-learn, TensorFlow, PyTorch – в зависимости от сложности и объёма данных.
   - Модель периодически переобучается (с помощью Airflow или cron-job).

4. **Сохранение результатов:**
   - Прогнозы, метрики, логи обработки – в Oracle (структурированные) или ClickHouse (аналитические).

5. **Визуализация:**
   - Dash/Plotly или React + Chart.js для интерактивных дашбордов.
   - Matplotlib/Seaborn для генерации статических отчётов.

6. **Развёртывание:**
   - Контейнеризация (Docker).
   - Kubernetes (при необходимости масштабирования и централизованного управления контейнерами).
   - CI/CD (Jenkins/GitLab CI) – автоматизация сборки, тестирования и развёртывания.

# 3. Обоснования выбора инструментов

1. Python – универсальный язык с богатой экосистемой библиотек и фреймворков для анализа данных (Pandas, NumPy, Scikit-learn).
2. Flask/FastAPI – лёгкие и гибкие фреймворки для быстрого создания RESTful API, легко интегрируются с ML-библиотеками.
3. Oracle – надёжное хранилище для реляционных данных, хорошо подходит для хранения бизнес-логики и связанных структурированных данных.
4. ClickHouse – эффективен для аналитики по временным рядам и работе с большими объёмами (подходит для данных с датчиков).
5. Scikit-learn, TensorFlow, PyTorch – стандартный набор инструментов для машинного обучения и дип-обучения.
6. Matplotlib/Seaborn – мощные библиотеки для научной визуализации и построения статических графиков.
7. Plotly/Dash – удобен для интерактивных веб-приложений и дашбордов, что упрощает доступ к аналитике не только разработчикам, но и конечным пользователям.
8. Docker – позволяет унифицировать среду исполнения и упрощает развёртывание.
9. Kubernetes – решение для управления контейнерами, если нужно масштабирование по нагрузке.